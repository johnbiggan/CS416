{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnbiggan/CS416/blob/main/Copy_of_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project notebook available in Google Colab space: https://colab.research.google.com/github/johnbiggan/DeepLearningforHealthcare-Project/blob/main/Code/Project.ipynb\n",
        "\n",
        "Public GitHub repo: https://github.com/johnbiggan/DeepLearningforHealthcare-Project/blob/main/Code/Project.ipynb\n",
        "\n",
        "and video presentation: [INSERT HTML HERE]"
      ],
      "metadata": {
        "id": "7YYD-33pLZz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Domain Knowledge Guided Deep Learning\n",
        "###with Electronic Health Records Replication"
      ],
      "metadata": {
        "id": "iHlDobF8_sW7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmYpM15nAQQR"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Every year, more than a quarter of all healthcare spending in the US is spent on preventable diseases [1]. In an effort to intervene earlier researchers look to the ever-growing pool of electronic health records (EHRs) to predict disease risk. Many models have been developed, but with the recurrent nature of healthcare visits recurrent neural networks (RNNs) have shown the most promise.\n",
        "\n",
        "Unfortunately, early RNNs treated the time between consecutive visits as well as the time between visits and disease diagnosis as unimportant. Additionally, other early models fail to incorporate medical knowledge in the form of relationships between diagnosis (e.g comorbid, causes, caused-by).\n",
        "\n",
        "The Domain Knowledge Guided Recurrent Neural Network (DG-RNN) being replicated in this project addresses both shortcomings and has been found to improve heart failure prediction over-and-above previous methodologies [2]. In their paper, the authors described a model that uses multiple long short-term memory models [3] with attention to utilize disease diagnoses, procedure codes, visit time differences, and a medical knowledge graph (Figure 1). Incorporating medical knowledge graphs provides challenges. For example, the semi-structured nature of graphs adds to the complexity. Moreover, readily-available medical knowledge graphs have been few and far between.\n",
        "\n",
        "Testing this model on the MIMIC-III dataset [4,5,6], it was able to outperform numerous other models, including random forests, support vector machines, and traditional long short-term memory RNNs on a heart failure prediction task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Figure 1](https://raw.githubusercontent.com/johnbiggan/DeepLearningforHealthcare-Project/main/Figures/Figure1.png \"Figure 1\")\n",
        "\n",
        "Figure 1. DG-RNN model."
      ],
      "metadata": {
        "id": "r1VOt02kNdXv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility\n",
        "\n",
        "This replication will focus on reproducing the main findings of the paper. Specifically, the following hypotheses will be tested:\n",
        "\n",
        "Hypothesis 1: Including the time between visits will improve the model over the base model that treats all visits in a simple sequential manner.\n",
        "\n",
        "Hypothesis 2: Including domain knowledge, along with the time between visits, will lead to a better performing model than the base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "Python version 3.11 was used.\n",
        "\n",
        "Additionally, this project uses tools from the pyhealth, numpy, pytorch, and pandas packages, which should be installed if they have not already been."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if not already installed\n",
        "! pip install pyhealth\n",
        "! pip install numpy\n",
        "! pip install torch torchvision torchaudio\n",
        "! pip install pandas"
      ],
      "metadata": {
        "id": "y5Cr-eC9_TLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "np.random.seed(1983)\n",
        "torch.manual_seed(1983)"
      ],
      "metadata": {
        "id": "iO80feJKNwVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIMIC-III\n",
        "\n",
        "For their model, the authors used a proprietary dataset as well as the MIMIC-III (Medical Information Mart for Intensive Care III) dataset [4,5,6], which is a freely available database for researchers consisting of deidentified health data from over 40,000 patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. It includes detailed demographics and visit-level healthcare data.\n",
        "\n",
        "Although the data is freely available to researchers, it is not publically available due to privacy concerns. Fortunately, in recent years pyhealth [7,8] contributors have created a synthetic dataset based on the MIMIC-III data that does not create the same privacy concerns. As this is a public-facing project, the synthetic MIMIC-III data from pyhealth will be used. However, the same analyses may be conducted with the original MIMIC-III dataset by changing the **root** argument to point at the original dataset."
      ],
      "metadata": {
        "id": "n2jgcV6fOz6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzVUQS0CHry0"
      },
      "outputs": [],
      "source": [
        "from pyhealth.datasets import MIMIC3Dataset\n",
        "from pyhealth.datasets import split_by_patient, get_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aYF3qCv_HvF"
      },
      "outputs": [],
      "source": [
        "base_dataset = MIMIC3Dataset(\n",
        "    root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/\",\n",
        "    tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
        "    code_mapping={\"ICD9CM\": \"CCSCM\", \"ICD9PROC\": \"CCSPROC\"},\n",
        "    dev=False,\n",
        "    refresh_cache=False,\n",
        ")\n",
        "base_dataset.stat()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PrimeKG\n",
        "\n",
        "For the knowledge graph, the authors originally used the KnowLife knowledge graph [9]. Unfortunately, at the time of this replication the KnowLife knowledge graph was no longer available.\n",
        "\n",
        "More recently, researchers have developed an updated medical knowledge graph called PrimeKG [10,11]. This appears to be a worthwhile alternative. One challenge was that the nodes are coded in Monarch Disease Ontology (MONDO) coding, for which there is not a simple mapping available to convert to ICD-9 or CCSCM codes, which is what the MIMIC-III dataset uses.\n",
        "\n",
        "To overcome this, a subset of the diseases was created by including only heart-related conditions and conditions with a connection to heart-related conditions. Specifically, only disease descriptions including the key words (heart, atrial, ventriclular, cardia, myocardial, and coronary) were kept. This resulted in 576 diseases to manually code with ICD-9 codes.\n",
        "\n",
        "Due to the fact that ICD-9 codes are not as granular as MONDO and other newer coding schemas (e.g. ICD-10), there were redundancies that meant that the final list of ICD-9 codes was reduced to 91 unique codes. This knowledge graph was then converted to CCSCM codes, which are typically used in pyhealth. This further reduced the total number of codes to 35 unique codes.\n",
        "\n",
        "Unfortunately, all of this conversion resulted in a loss of granularity, which may have worsened the performance of the final model. However, this still allowed for a comparison of models with and without some information via a knowledge graph."
      ],
      "metadata": {
        "id": "32vMvDdURIMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import knowledge graph\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV data into a pandas DataFrame\n",
        "url = \"https://raw.githubusercontent.com/johnbiggan/DeepLearningforHealthcare-Project/main/Data/icd_graph_structure.csv\"\n",
        "kg = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "kg.head()"
      ],
      "metadata": {
        "id": "dlOXfrsuZ1Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ICD-9 to CCSCM for knowledge graph\n",
        "from pyhealth.medcode import CrossMap\n",
        "\n",
        "mapping = CrossMap.load(source_vocabulary=\"ICD9CM\", target_vocabulary=\"CCSCM\")\n",
        "\n",
        "kg_ccscm = {}\n",
        "\n",
        "# Iterate through the DataFrame and convert from ICD-9 to CCSCM\n",
        "for index, row in kg.iterrows():\n",
        "    ccscm_id = mapping.map(row['x_icd_id'])\n",
        "    ccscm_set = set()\n",
        "\n",
        "    if ccscm_id:\n",
        "        ccscm_id = ccscm_id[0]\n",
        "\n",
        "        for y_icd_id in eval(row['y_icd_id']):\n",
        "            y_ccscm_id = mapping.map(y_icd_id)\n",
        "            if y_icd_id != \"\" and y_ccscm_id != ccscm_id and y_ccscm_id:\n",
        "                ccscm_set.add(y_ccscm_id[0])\n",
        "\n",
        "        kg_ccscm[ccscm_id] = ccscm_set\n",
        "\n",
        "print(\"The CCSCM coded graph contains\", len(kg_ccscm), \"primary codes.\")"
      ],
      "metadata": {
        "id": "l6EVrte-cWL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsLJXUBQ_HvF"
      },
      "outputs": [],
      "source": [
        "# Confirm the CCSCM code for conjestive heart failure to be used in the labeling task\n",
        "from pyhealth.medcode import InnerMap\n",
        "\n",
        "mapping = CrossMap.load(source_vocabulary=\"ICD9CM\", target_vocabulary=\"CCSCM\")\n",
        "print(\"The CCSCM code that maps to ICD-9 code 428.0 (conjestive heart failure) is\", mapping.map(\"428.0\"))\n",
        "print(\"The CCSCM code that maps to ICD-9 code 428.9 (conjestive heart failure) is\", mapping.map(\"428.9\"))\n",
        "\n",
        "ccscm = InnerMap.load(\"CCSCM\")\n",
        "print(\"Confirmation that CCSCM code '108' corresponds to\", ccscm.lookup(\"108\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWOyusf9_HvF"
      },
      "outputs": [],
      "source": [
        "# Create custom visit time difference calculation and heart failure prediction task\n",
        "from pyhealth.data import Patient, Visit\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def visit_time_diff_mimic3_fn(patient: Patient):\n",
        "    \"\"\"Processes a single patient for the visit time difference task.\n",
        "\n",
        "    Visit time difference calculates the delay between the current visit and\n",
        "    the previous visit.\n",
        "\n",
        "    Args:\n",
        "        patient: a Patient object\n",
        "\n",
        "    Returns:\n",
        "        samples: a list of samples, each sample is a dict with patient_id,\n",
        "            visit_id, and other task-specific attributes as key\n",
        "\n",
        "    Examples:\n",
        "        >>> from pyhealth.datasets import MIMIC3Dataset\n",
        "        >>> mimic3_base = MIMIC3Dataset(\n",
        "        ...    root=\"/srv/local/data/physionet.org/files/mimiciii/1.4\",\n",
        "        ...    tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
        "        ...    code_mapping={\"ICD9CM\": \"CCSCM\"},\n",
        "        ... )\n",
        "        >>> from pyhealth.tasks import hf_prediction_mimic3_fn\n",
        "        >>> mimic3_sample = mimic3_base.set_task(visit_time_diff_mimic3_fn)\n",
        "        >>> mimic3_sample.samples[0]\n",
        "        [{'visit_id': '130744', 'patient_id': '103', 'conditions': [['129', '157', '99', '101', '110', '55', '62', '105', '4', '63', '138']], 'related_conditions': [['96', '238', '108', '95', '47', '213', '104', '105']], 'procedures': [['1']], 'visit_diff': [[0.0, 0.0, 0.0, 0.0]] 'label': 0}]\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    criterion_time = None\n",
        "\n",
        "    for i in range(len(patient) - 1):\n",
        "        visit: Visit = patient[i]\n",
        "        visit_time = visit.encounter_time\n",
        "\n",
        "        next_visit: Visit = patient[i + 1]\n",
        "        hf_label = 0\n",
        "\n",
        "        if '108' not in next_visit.get_code_list(table=\"DIAGNOSES_ICD\"):\n",
        "            hf_label = 0\n",
        "        else:\n",
        "            hf_label = 1\n",
        "\n",
        "        visit_diff = []\n",
        "\n",
        "        if i > 0:\n",
        "            prev_visit: Visit = patient[i - 1]\n",
        "            prev_visit_time = prev_visit.encounter_time\n",
        "\n",
        "            # Find criterion time (i.e. first encounter with HF diagnosis)\n",
        "            for j in range(len(patient) - 1):\n",
        "                c_visit: Visit = patient[j]\n",
        "                if criterion_time == None and '108' in c_visit.get_code_list(table=\"DIAGNOSES_ICD\"):\n",
        "                    criterion_time = c_visit.encounter_time\n",
        "\n",
        "            if criterion_time != None:\n",
        "                v_c_s = np.sin(((visit_time - criterion_time).days)/10000).item()\n",
        "                v_c_c = np.cos(((visit_time - criterion_time).days)/10000).item()\n",
        "            else:\n",
        "                v_c = 0.0\n",
        "                v_c_s = 0.0\n",
        "                v_c_c = 0.0\n",
        "\n",
        "            v_p = visit_time - prev_visit_time\n",
        "\n",
        "            visit_diff = [\n",
        "                v_c_s,\n",
        "                v_c_c,\n",
        "                np.sin(((v_p).days)/10000).item(),\n",
        "                np.cos(((v_p).days)/10000).item()\n",
        "            ]\n",
        "\n",
        "        else:\n",
        "            visit_diff = [0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "        related_conditions = set()\n",
        "\n",
        "        for ccscm_id, ccscm_values in kg_ccscm.items():\n",
        "            if ccscm_id in visit.get_code_list(table=\"DIAGNOSES_ICD\"):\n",
        "                for related_id in ccscm_values:\n",
        "                    related_conditions.add(related_id)\n",
        "\n",
        "        if not related_conditions:\n",
        "            related_conditions.add('9999') # add dummy code if no related conditions\n",
        "\n",
        "        conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
        "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
        "        # exclude: visits without condition and procedure code\n",
        "        if len(conditions) * len(procedures) == 0 or len(patient) < 2:\n",
        "            continue\n",
        "        samples.append(\n",
        "            {\n",
        "                \"visit_id\": visit.visit_id,\n",
        "                \"patient_id\": patient.patient_id,\n",
        "                \"conditions\": [conditions],\n",
        "                \"related_conditions\": [list(related_conditions)],\n",
        "                \"procedures\": [procedures],\n",
        "                \"visit_diff\": [visit_diff],\n",
        "                \"label\": hf_label,\n",
        "            }\n",
        "        )\n",
        "    # no cohort selection\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFsqr4s6_HvG"
      },
      "outputs": [],
      "source": [
        "# Create a sample dataset with a label to indicate an HF diagnosis and visit difference vector\n",
        "sample_dataset = base_dataset.set_task(visit_time_diff_mimic3_fn)\n",
        "sample_dataset.stat()\n",
        "\n",
        "# Split dataset into training, validation, and testing using an 80%, 10%, 10% split\n",
        "train_dataset, val_dataset, test_dataset = split_by_patient(\n",
        "    sample_dataset, [0.8, 0.1, 0.1]\n",
        ")\n",
        "\n",
        "train_dataloader = get_dataloader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = get_dataloader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_dataloader = get_dataloader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View a single patient\n",
        "print(sample_dataset[9]) #9"
      ],
      "metadata": {
        "id": "uGadm3-3bkFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   DG-RNN Model\n",
        "The domain-guided recurrent neural network (DG-RNN) uses multiple long short-term memory units that incorporate both length between visits and domain knowledge from a knowledge graph of related conditions (see Figure 1).\n",
        "  * Model architecture [2]:\n",
        "    * **Embedding Layer:** Converts medical event codes into dense vectors, capturing semantic similarities among codes.\n",
        "    * **LSTM Layer:** Utilizes Long Short-Term Memory units to model sequences of medical events. The LSTM handles variable-length input sequences, crucial for EHR data where each patient's record may differ in length.\n",
        "    * **Knowledge Graph Attention Mechanism:** Dynamically integrates external domain knowledge (from a medical knowledge graph) into the LSTM outputs at each time step. This layer selectively enhances the LSTM output with information relevant to the current patient state.\n",
        "    * **Global Max Pooling Layer:** Aggregates all LSTM outputs across the time dimension, to summarize the entire input sequence effectively.\n",
        "    * **Fully Connected Layer:** A dense layer that transforms the pooled LSTM outputs into final prediction logits.\n",
        "    * **Output Activation Function:** Sigmoid\n",
        "\n",
        "&dagger;Original paper repo is available at https://github.com/AIMedLab/DG-RNN/tree/master."
      ],
      "metadata": {
        "id": "TQRii3qtH_oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.models import RNN\n",
        "from pyhealth.trainer import Trainer\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "lIoFM-W3VbJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple LSTM without knowledge graph or time\n",
        "base_model = RNN(\n",
        "    dataset=sample_dataset,\n",
        "    feature_keys=[\"conditions\", \"procedures\"],\n",
        "    label_key=\"label\",\n",
        "    mode=\"binary\",\n",
        "    rnn_type=\"LSTM\",\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        ")"
      ],
      "metadata": {
        "id": "HVIUXdx8YutU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple LSTM without knowledge graph\n",
        "time_model = RNN(\n",
        "    dataset=sample_dataset,\n",
        "    feature_keys=[\"conditions\", \"procedures\", \"visit_diff\"],\n",
        "    label_key=\"label\",\n",
        "    mode=\"binary\",\n",
        "    rnn_type=\"LSTM\",\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        ")"
      ],
      "metadata": {
        "id": "BHlL44o-Hvbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create full model\n",
        "full_gn_rnn_model = RNN(\n",
        "    dataset=sample_dataset,\n",
        "    feature_keys=[\"conditions\", \"related_conditions\", \"procedures\", \"visit_diff\"],\n",
        "    label_key=\"label\",\n",
        "    mode=\"binary\",\n",
        "    rnn_type=\"LSTM\",\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        ")"
      ],
      "metadata": {
        "id": "u3sO_3Ykau7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Training\n",
        "Training was completed using 80% of the MIMIC-III dataset, randomly sampled. A 10% validation set was also used.\n",
        "  * Hyperparameters:\n",
        "    * **Loss Function:** Binary Cross Entropy\n",
        "    * **Optimizer:** Adam\n",
        "    * **Learning Rate:** 0.0001\n",
        "  * Computational Requirements:\n",
        "    * **Type of Hardware:** CPU\n",
        "    * **Average Runtime per Epoch:**\n",
        "      * Base model = .73 seconds\n",
        "      * Model with time = 1.03 seconds\n",
        "      * Full model = 1.34 seconds\n",
        "    * **Number of Training Epochs:** 50"
      ],
      "metadata": {
        "id": "l7NY02bQt7Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model training\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "base_trainer = Trainer(model=base_model)\n",
        "base_trainer.train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    epochs=50,\n",
        "    optimizer_class=torch.optim.Adam,\n",
        "    optimizer_params={\"lr\": 1e-4},\n",
        "    monitor=\"roc_auc\",\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"Training started at: {start_time}\")\n",
        "print(f\"Training ended at: {end_time}\")\n",
        "print(f\"Total elapsed time: {end_time - start_time}\")\n",
        "print(f\"Average epoch time: {(end_time - start_time)/50}\")"
      ],
      "metadata": {
        "id": "Z3E35FT4TdoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model w/time training\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "time_trainer = Trainer(model=time_model)\n",
        "time_trainer.train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    epochs=50,\n",
        "    optimizer_class=torch.optim.Adam,\n",
        "    optimizer_params={\"lr\": 1e-4},\n",
        "    monitor=\"roc_auc\",\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"Training started at: {start_time}\")\n",
        "print(f\"Training ended at: {end_time}\")\n",
        "print(f\"Total elapsed time: {end_time - start_time}\")\n",
        "print(f\"Average epoch time: {(end_time - start_time)/50}\")"
      ],
      "metadata": {
        "id": "cliErrhhHvpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full model training\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "full_gn_rnn_trainer = Trainer(model=full_gn_rnn_model)\n",
        "full_gn_rnn_trainer.train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    epochs=50,\n",
        "    optimizer_class=torch.optim.Adam,\n",
        "    optimizer_params={\"lr\": 1e-4},\n",
        "    monitor=\"roc_auc\",\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"Training started at: {start_time}\")\n",
        "print(f\"Training ended at: {end_time}\")\n",
        "print(f\"Total elapsed time: {end_time - start_time}\")\n",
        "print(f\"Average epoch time: {(end_time - start_time)/50}\")"
      ],
      "metadata": {
        "id": "zd40vzALJ_5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "All three models were evaluated using a test set of 10% of the original dataset that was held out for testing. The metric of interest was the area under the receiver operating characteristic curve (AUROC), which provides a measure of model performance in binary classification tasks where scores range from 0-1 and higher scores indicate better model performance. Note that all three models were tested on the same set."
      ],
      "metadata": {
        "id": "f5K9X3Eu10lU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sejoFOah_HvI"
      },
      "outputs": [],
      "source": [
        "# Simple DG-RNN model performance\n",
        "\n",
        "print(base_trainer.evaluate(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple DG-RNN model performance with time added\n",
        "\n",
        "print(time_trainer.evaluate(test_dataloader))"
      ],
      "metadata": {
        "id": "rYPIVAjdH-77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full DG-RNN model performance\n",
        "\n",
        "print(full_gn_rnn_trainer.evaluate(test_dataloader))"
      ],
      "metadata": {
        "id": "MKzPYUmPQuhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "Similar to the models presented in the original paper, more information in the model led to improved overall performance (Table 1). For instance, the full model (AUROC = 0.5790) outperformed the partial model that included the time component, but not the knowledge graph information (AUROC = 0.5647), which outperformed the base model with no time or knowledge graph information (AUROC = 0.5629).\n",
        "\n",
        "These findings support both hypotheses, such that with each additional piece of information, the model improved in its predictive performance."
      ],
      "metadata": {
        "id": "eO17Oye-dJ1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Table 1.* Model AUROC values.\n",
        "\n",
        "| Full Model | Model w/o KG | Simple Model w/o Time or KG |\n",
        "|----------|----------|----------|\n",
        "|    0.5790     |    0.5647     |    0.5629     |\n"
      ],
      "metadata": {
        "id": "rJkv78gkplbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison\n",
        "\n",
        "The authors reported an AUROC of 0.7375 for the full DG-RNN model on the MIMIC-III dataset [2]. They also report lowered performance (AUROC = 0.7238) for the simpler model without the knowledge graph included.\n",
        "\n",
        "For this replication, there was a similar pattern, but the overall AUROC was considerably lower across the board. The possible reasons for the lowered performance is discussed below.\n",
        "\n",
        "The full model that included both the time component and the additional information from the knowledge graph outperformed (AUROC = 0.5790) the model with only the time component (AUROC = 0.5647), which outperformed the simplest model with no time or knowledge graph information (AUROC = 0.5629).\n",
        "\n",
        "While the predictive ability was lower overall for the replication models, they display the same pattern as the original results. This replicates the finding that adding further knowledge of interconnections can improve model performance and enhance predicitve ability."
      ],
      "metadata": {
        "id": "lyEZt13lPCtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "This model supports the overarching claim from the original authors that adding timing information and knowledge about disease relationships can enhance an RNN over-and-above the base model in a heart failure prediction task [2].\n",
        "\n",
        "In this replication pyhealth [7,8] was used where possible as it simplifies data pre-processing, model building/training, and model evaluation. In addition to simplifying the process, the resulting code is more human-readable. Overall, using pyhealth has made the reproduction easier than it would have been otherwise and more portable to show to less technical audiences.\n",
        "\n",
        "The largest challenge faced had to do with the knowledge graph. The one that the original authors used [9] no longer appears to be available and the other knowledge graphs that were explored had their own challenges. For instance, the knowledge graph, PrimeKG [10], that ended up being used was extensive, but used a medical coding style, MONDO, that was difficult to translate to ICD-9 and CCSCM codes.\n",
        "\n",
        "In order to make this knowledge graph work with the MIMIC-III dataset, the diagnostic codes needed to be manually coded into an ICD-9 format. Not only is this prone to human error, but as the original dataset consisted of 6,392 individual nodes and numerous connections, the dataset had to be focused to only disease-related codes and only those that were related on the heart. Between this reduction, the conversion to the less granular ICD-9 codes, and the further conversion to even less granular CCSCM codes, a lot of information that may have been predictive of heart failure at the next visit was lost. This likely led, in part, to the lower AUROC score for the model.\n",
        "\n",
        "Another possible reason for the reduced performance relative to what was reported in the paper, may have to do with the fact that the datasets used were not exactly the same. Since this is public, the synthesized version of the MIMIC-III dataset [8] was used instead of the original MIMIC-III dataset. Moreover, the original article also used data from a proprietary source that was not available for this replication. Those two factors may also have figured into the differences in overall magnitude of the model performance. Future replication that is not public facing may be improved with the use of the original MIMIC-III and proprietary datasets.\n",
        "\n",
        "That being said, the replication showed the same pattern of results as the original article. This is important in that it demonstrates that visit timing and enhanced knowledge base can be used to enhance the predictive quality of a model and may allow physicians to intervene sooner, resulting in better outcomes for patients. Additionally, this replication was accomplished using a new package, pyhealth, that could make this type of model simpler to implement in clincal settings. Future research should expand on this by generalizing to other diseases."
      ],
      "metadata": {
        "id": "_WJDsqqEbU6v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1.   Bolnick, H. J., Bui, A. L., Bulchis, A., Chen, C., Chapin, A., Lomsadze, L., ... Dieleman, J. L. (2020). Health-care spending attributable to modifiable risk factors in the USA: An economic attribution analysis. The Lancet Public Health, 5(10), e525-e535. https://doi.org/10.1016/S2468-2667(20)30203-6\n",
        "2.   Yin, C., Zhao, R., Qian, B., Lv, X., & Zhang, P. (2019). Domain Knowledge Guided Deep Learning with Electronic Health Records. In 2019 IEEE International Conference on Data Mining (ICDM) (pp. 738-747). Beijing, China. https://doi.org/10.1109/ICDM.2019.00084\n",
        "3.   Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780. https://doi.org/10.1162/neco.1997.9.8.1735\n",
        "4.   Johnson, A., Pollard, T., & Mark, R. (2016). MIMIC-III Clinical Database (version 1.4). PhysioNet. https://doi.org/10.13026/C2XW26.\n",
        "5.   Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.\n",
        "6.   Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.\n",
        "7.   Yang, C., Wu, Z., Jiang, P., Lin, Z., Gao, J., Danek, B. P., & Sun, J. (2023). PyHealth: A Deep Learning Toolkit for Healthcare Applications. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 5788–5789). New York, NY, USA: Association for Computing Machinery.\n",
        "8.   Theodorou, B., Xiao, C., & Sun, J. (2023). Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model. Nature Communications, 14, 5305. https://doi.org/10.1038/s41467-023-41093-0\n",
        "8.   Ernst, P., Siu, A., & Weikum, G. (2015). Knowlife: A versatile approach for constructing a large knowledge graph for biomedical sciences. BMC Bioinformatics.\n",
        "9.   Chandak, P., Huang, K., & Zitnik, M. (2023). Building a knowledge graph to enable precision medicine. Scientific Data, 10(1), Article 67. https://doi.org/10.1038/s41597-023-01960-3\n",
        "10.   Chandak, P. (2022). PrimeKG (V2) [Data set]. Harvard Dataverse. https://doi.org/10.7910/DVN/IXA7BM"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}